{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECOND ASSIGNMENT. MACHINE LEARNING WITH SCIKIT-LEARN. \n",
    "## PART I (1.5 POINTS)\n",
    "\n",
    "The aim of part I of the Scikit-learn assignment is for you to self-learn and get used to this Machine Learning tool. The main part (part II) of the assignment will be explained next week (11/12). \n",
    "\n",
    "Here, you will learn to:\n",
    "\n",
    "- Perform a crossvalidation on the iris classification problem with decision trees (so far, we have only done regression)\n",
    "- Perform a crossvalidation on the iris classification problem **with KNN** (I haven't explained this, you will have to learn how to use it from the web)\n",
    "- Perform grid search in order to determine the best value for hyper-parameter K\n",
    "\n",
    "You will also have to go through two notebooks I have prepared for you in order to see how crossvalidation and hyper-parameter tuning are used in Scikit-learn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Carry out the \"DECISION TREES WITH A TRAINING AND A TESTING SET AND CROSSVALIDATION\" notebook and understand the main ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perform a crossvalidation on the iris classification problem with decision trees:\n",
    "\n",
    "** It is important to remember that for classification, you have to use**\n",
    "- clf = tree.DecisionTreeClassifier() # for constructing the classifier\n",
    "- metrics.accuracy # for computing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy estimation: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "cv = KFold(X.shape[0], 10, shuffle=True) # getting a random partition\n",
    "scores = cross_val_score(tree.DecisionTreeClassifier(),X, y,\n",
    "                         scoring='accuracy', \n",
    "                         cv = cv)\n",
    "\n",
    "print(\"CV accuracy estimation: \"+str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTARIES:**\n",
    "\n",
    "Being imported from sklearn and from numpy what we need, we load iris dataset and set x as the attibutes and target as the classes. \n",
    "\n",
    "With the function KFold we specify we want a random partition of 10 sets of the data .\n",
    "\n",
    "cross_val_scores function performs the cross validation for the decision tree classifier, scoring the accuracy using the cv partition (output of the KFold function we used before). Finally we print the mean accuracy estimation as our estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform a crossvalidation on the iris classification problem with KNN\n",
    "\n",
    "I haven't explained how to use KNN in Scikit-learn. You will have to read and obtain the relevant information [here](http://scikit-learn.org/stable/modules/neighbors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy estimation: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors as NN\n",
    "\n",
    "scores = cross_val_score(NN.KNeighborsClassifier(),X, y,\n",
    "                         scoring='accuracy',cv = cv) # default K=5\n",
    "\n",
    "print(\"CV accuracy estimation: \"+str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTARIES:**\n",
    "\n",
    "We do exactly the same except for the method we want to stimate the accuracy. In this case is KNeighborsClassifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Try different values for K (KNN) - change them by hand- and see if you obtain a better result than with KNN default value. Always use crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1 neighbors: CV accuracy estimation= 0.96\n",
      "\n",
      "K = 2 neighbors: CV accuracy estimation= 0.946666666667\n",
      "\n",
      "K = 3 neighbors: CV accuracy estimation= 0.96\n",
      "\n",
      "K = 4 neighbors: CV accuracy estimation= 0.96\n",
      "\n",
      "K = 5 neighbors: CV accuracy estimation= 0.966666666667\n",
      "\n",
      "K = 6 neighbors: CV accuracy estimation= 0.953333333333\n",
      "\n",
      "K = 7 neighbors: CV accuracy estimation= 0.96\n",
      "\n",
      "K = 8 neighbors: CV accuracy estimation= 0.973333333333\n",
      "\n",
      "K = 9 neighbors: CV accuracy estimation= 0.966666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    scores=cross_val_score(NN.KNeighborsClassifier(n_neighbors=i),X, y,scoring='accuracy',cv = cv)\n",
    "    print(\"K = \"+ str(i)+\" neighbors: \" +\"CV accuracy estimation= \"+str(np.mean(scores)) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8984eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Ktop=50\n",
    "scores=[]\n",
    "\n",
    "for i in range(1,Ktop):\n",
    "    errors=cross_val_score(NN.KNeighborsClassifier(n_neighbors=i),X, y,scoring='accuracy',cv = cv)\n",
    "    scores.append(np.mean(errors))\n",
    "\n",
    "plt.plot(scores,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTARIES:**\n",
    "\n",
    "Keeping the same partition for cross validation and changing from 1 to 50 the hyperparameter \"number of neighbours\" in the algorithm, we could say that the best value of the hyperparameter is K=8 (in this case, it gives us the highest accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Carry out THE \"DECISION TREE HYPER-PARAMETERS. TUNING DECISION TREES\" notebook and understand the main ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. USE GRID SEARCH AND RANDOMIZED SEARCH TO FIND THE OPTIMAL VALUE FOR K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "Wall time: 535 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 245 out of 245 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 6}, 0.98)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "np.random.seed(0)\n",
    "param_grid = {'n_neighbors': range(1,50,1)}\n",
    "\n",
    "clf = GridSearchCV(NN.KNeighborsClassifier(), \n",
    "                   param_grid,\n",
    "                   scoring='accuracy',\n",
    "                   cv=5 , n_jobs=1, verbose=1)\n",
    "%time _ = clf.fit(X,y)\n",
    "\n",
    "\n",
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTARIES:**\n",
    "\n",
    "Being imported the function GridSearchCV, we specify the param_grid in which there are all the possible values for the hyperparameter n_neighbors (from 1 to 50).\n",
    "\n",
    "Then we apply GridSearchCV for the method KNeighborsClassifier scoring the accuracy with 5-fold-crossvalidation.\n",
    "\n",
    "Finally, we see the time it took and also the best parameter (K=6) with its accuracy score (0.98)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RANDOMIZED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "mean: 0.96667, std: 0.02108, params: {'n_neighbors': 3}\n",
      "mean: 0.97333, std: 0.02494, params: {'n_neighbors': 5}\n",
      "mean: 0.96667, std: 0.02981, params: {'n_neighbors': 8}\n",
      "mean: 0.98000, std: 0.02667, params: {'n_neighbors': 11}\n",
      "mean: 0.98000, std: 0.02667, params: {'n_neighbors': 12}\n",
      "mean: 0.96667, std: 0.02981, params: {'n_neighbors': 16}\n",
      "mean: 0.96667, std: 0.02981, params: {'n_neighbors': 19}\n",
      "mean: 0.94667, std: 0.03399, params: {'n_neighbors': 27}\n",
      "mean: 0.94000, std: 0.03887, params: {'n_neighbors': 28}\n",
      "mean: 0.93333, std: 0.04216, params: {'n_neighbors': 29}\n",
      "mean: 0.94000, std: 0.03887, params: {'n_neighbors': 30}\n",
      "mean: 0.93333, std: 0.04216, params: {'n_neighbors': 31}\n",
      "mean: 0.94667, std: 0.03399, params: {'n_neighbors': 32}\n",
      "mean: 0.94000, std: 0.03887, params: {'n_neighbors': 33}\n",
      "mean: 0.95333, std: 0.02667, params: {'n_neighbors': 34}\n",
      "mean: 0.95333, std: 0.02667, params: {'n_neighbors': 35}\n",
      "mean: 0.93333, std: 0.04216, params: {'n_neighbors': 38}\n",
      "mean: 0.94000, std: 0.03266, params: {'n_neighbors': 41}\n",
      "mean: 0.92667, std: 0.03887, params: {'n_neighbors': 47}\n",
      "mean: 0.94000, std: 0.03887, params: {'n_neighbors': 49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 11}, 0.98)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "np.random.seed(0)\n",
    "\n",
    "param_dist = {'n_neighbors': range(1,50,1)}\n",
    "\n",
    "n_iter_search = 20\n",
    "clfrs = RandomizedSearchCV(NN.KNeighborsClassifier(), \n",
    "                                   param_distributions=param_dist,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=5 , n_jobs=1, verbose=1,\n",
    "                                   n_iter=n_iter_search)\n",
    "clfrs.fit(X,y)\n",
    "clfrs.grid_scores_.sort()\n",
    "for line in clfrs.grid_scores_[0:25]:\n",
    "    print(line)\n",
    "    \n",
    "clfrs.best_params_, clfrs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTARIES:**\n",
    "\n",
    "Being imported the function RandomizedSearchCV, we specify the param_dist in which it is going to do the random search for possible values for the hyperparameter n_neighbors (from 1 to 50).\n",
    "\n",
    "Then we apply RandomizedSearchCV (specifying previously n_iter_search = 20) for the method KNeighborsClassifier scoring the accuracy with 5-fold-crossvalidation. \n",
    "\n",
    "Finally, we see the time it took (obviously in this case less time) and also the best parameter (K=11) with its accuracy score (0.98).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. OPTIONAL (you may get 0.25 extra points if you decide to do this). \n",
    "\n",
    "K is the main hyper-parameter of KNN. Find another hyper-parameter that you consider relevant, and try to optimize both K and the other parameter using grid-search. Are you able to improve on previous results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 392 candidates, totalling 1960 fits\n",
      "Wall time: 4.07 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1960 out of 1960 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance'},\n",
       " 0.9866666666666667)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "np.random.seed(0)\n",
    "param_grid = {'n_neighbors': range(1,50,1),\n",
    "              'weights':('uniform', 'distance'),\n",
    "              'metric':('euclidean','manhattan','chebyshev','minkowski')}\n",
    "\n",
    "clf = GridSearchCV(NN.KNeighborsClassifier(), \n",
    "                   param_grid,\n",
    "                   scoring='accuracy',\n",
    "                   cv=5 , n_jobs=1, verbose=1)\n",
    "%time _ = clf.fit(X,y)\n",
    "\n",
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTARIES:**\n",
    "    \n",
    "We decided to include the hyperparameters:\n",
    "\n",
    "- Weights: Uniform if we give the same importance for the K nearest neighbors, or Distance if we give weighted importance depending on the distance (the closer the more) for the K nearest neighbours.\n",
    "\n",
    "- Metric: Using the following different distances ir order to calculate the K nearest neighbours: Euclidean, Manhatan, Chebyshev and Minkoski.\n",
    "\n",
    "Then the process is exactly the same we have done for grid search, obtaining the best hyperparameters: 'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance',  with its accuracy score (0.98)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
